{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.models.train_model import test_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.externals import joblib\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.7 s, sys: 34.3 s, total: 49 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Reading and resampling 10% from the original size\n",
    "with open('../data/interim/X_train.pkl', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open('../data/interim/y_train.pkl', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open('../data/interim/X_hold1.pkl', 'rb') as f:\n",
    "    X_hold1 = pickle.load(f)\n",
    "with open('../data/interim/y_hold1.pkl', 'rb') as f:\n",
    "    y_hold1 = pickle.load(f)\n",
    "with open('../data/interim/cols_to_keep_rf.pkl', 'rb') as f:\n",
    "    cols_to_keep_rf = pickle.load(f)\n",
    "with open('../data/interim/cols.pkl', 'rb') as f:\n",
    "    cols = pickle.load(f)\n",
    "X_cols = [c in cols_to_keep_rf for c in cols]\n",
    "np.random.seed(seed=42)\n",
    "randomized_index = np.random.choice(X_train.shape[0], size=int(X_train.shape[0]/10), replace=False)\n",
    "X_train = X_train[randomized_index, :][:, X_cols]\n",
    "y_train = y_train[randomized_index]\n",
    "X_hold1 = X_hold1[:, X_cols]\n",
    "if not os.path.isfile('../data/interim/X_train_downsampled.pkl'):\n",
    "    with open('../data/interim/X_train_downsampled.pkl', 'wb') as f:\n",
    "        pickle.dump(X_train, f, pickle.HIGHEST_PROTOCOL)\n",
    "if not os.path.isfile('..data/interim/y_train_downsampled.pkl'):\n",
    "    with open('../data/interim/y_train_downsampled.pkl', 'wb') as f:\n",
    "        pickle.dump(y_train, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624503, 95)\n",
      "(624503,)\n",
      "(892148, 95)\n",
      "140\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_hold1.shape)\n",
    "print(len(cols))\n",
    "print(len(cols_to_keep_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: categorical_crossentropy\n",
      "Train on 437152 samples, validate on 187351 samples\n",
      "Epoch 1/30\n",
      "437152/437152 [==============================] - 71s 162us/step - loss: 8.0485 - acc: 0.5007 - val_loss: 8.0643 - val_acc: 0.4997\n",
      "Epoch 2/30\n",
      "437152/437152 [==============================] - 77s 177us/step - loss: 8.0486 - acc: 0.5006 - val_loss: 8.0643 - val_acc: 0.4997\n",
      "Epoch 3/30\n",
      "437152/437152 [==============================] - 81s 186us/step - loss: 8.0486 - acc: 0.5006 - val_loss: 8.0643 - val_acc: 0.4997\n",
      "CPU times: user 8min, sys: 41.9 s, total: 8min 41s\n",
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = X_train.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(n_cols, activation='relu', input_shape=(n_cols, )))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(n_cols, activation='relu'))\n",
    "\n",
    "# Add the third layer\n",
    "model.add(Dense(45, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, to_categorical(y_train), validation_split=0.3, epochs=30, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(X_hold1)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:, 1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999988788734921"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_hold1, predicted_prob_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999983998771106"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, model.predict(X_train)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892148,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_prob_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    892147\n",
       "1.0         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predicted_prob_true).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class printAUC(callbacks.Callback):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        super(printAUC, self).__init__()\n",
    "        self.bestAUC = 0\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        pred = self.model.predict(np.array(self.X_train))\n",
    "        auc = roc_auc_score(self.y_train, pred)\n",
    "        print(\"Train AUC: \" + str(auc))\n",
    "        pred = self.model.predict(self.validation_data[0])\n",
    "        auc = roc_auc_score(self.validation_data[1], pred)\n",
    "        print (\"Validation AUC: \" + str(auc))\n",
    "        if (self.bestAUC < auc) :\n",
    "            self.bestAUC = auc\n",
    "            self.model.save(\"bestNet.h5\", overwrite=True)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 624503 samples, validate on 892148 samples\n",
      "Epoch 1/20\n",
      " - 204s - loss: 0.6939 - acc: 0.4993 - val_loss: 0.6935 - val_acc: 0.5001\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 2/20\n",
      " - 173s - loss: 0.6934 - acc: 0.4988 - val_loss: 0.6931 - val_acc: 0.4999\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 3/20\n",
      " - 177s - loss: 0.6934 - acc: 0.4993 - val_loss: 0.6932 - val_acc: 0.4999\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 4/20\n",
      " - 183s - loss: 0.6933 - acc: 0.5005 - val_loss: 0.6932 - val_acc: 0.4999\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 5/20\n",
      " - 182s - loss: 0.6933 - acc: 0.4996 - val_loss: 0.6937 - val_acc: 0.4999\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 6/20\n",
      " - 195s - loss: 0.6933 - acc: 0.4988 - val_loss: 0.6932 - val_acc: 0.5001\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 7/20\n",
      " - 191s - loss: 0.6933 - acc: 0.4999 - val_loss: 0.6933 - val_acc: 0.4999\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 8/20\n",
      " - 192s - loss: 0.6933 - acc: 0.4995 - val_loss: 0.6937 - val_acc: 0.4999\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 9/20\n",
      " - 194s - loss: 0.6933 - acc: 0.5005 - val_loss: 0.6933 - val_acc: 0.5001\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 10/20\n",
      " - 190s - loss: 0.6933 - acc: 0.4993 - val_loss: 0.6934 - val_acc: 0.5001\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 11/20\n",
      " - 172s - loss: 0.6933 - acc: 0.5001 - val_loss: 0.6932 - val_acc: 0.5001\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 12/20\n",
      " - 366s - loss: 0.6933 - acc: 0.5005 - val_loss: 0.6932 - val_acc: 0.5001\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 13/20\n",
      " - 414s - loss: 0.6933 - acc: 0.5004 - val_loss: 0.6934 - val_acc: 0.5001\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 14/20\n",
      " - 513s - loss: 0.6933 - acc: 0.4992 - val_loss: 0.6931 - val_acc: 0.4999\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 15/20\n",
      " - 578s - loss: 0.6933 - acc: 0.4995 - val_loss: 0.6932 - val_acc: 0.5001\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 16/20\n",
      " - 576s - loss: 0.6933 - acc: 0.4992 - val_loss: 0.6933 - val_acc: 0.5001\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 17/20\n",
      " - 600s - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4999\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 18/20\n",
      " - 749s - loss: 0.6932 - acc: 0.5008 - val_loss: 0.6933 - val_acc: 0.4999\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 19/20\n",
      " - 617s - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5001\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "Epoch 20/20\n",
      " - 615s - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6932 - val_acc: 0.5001\n",
      "Train AUC: 0.5\n",
      "Validation AUC: 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x164760e10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BUILD MODEL\n",
    "model = Sequential()\n",
    "model.add(Dense(100,input_dim=n_cols))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(lr=0.01), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "annealer = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** x)\n",
    "\n",
    "# TRAIN MODEL\n",
    "model.fit(X_train,y_train, batch_size=32, epochs = 20, callbacks=[annealer,\n",
    "          printAUC(X_train, y_train)], validation_data = (X_hold1,y_hold1), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microsoft_malware",
   "language": "python",
   "name": "microsoft_malware"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
