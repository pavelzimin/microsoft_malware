import pandas as pd
import numpy as np
from sklearn.metrics import recall_score, precision_score, confusion_matrix, accuracy_score, log_loss, auc, \
    matthews_corrcoef, f1_score, fbeta_score, roc_auc_score
import random
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import ParameterGrid
import keras
from keras.layers import Dense, Embedding, Reshape, Add, Concatenate, Input, Dropout
from keras.models import Sequential, Model
from keras.utils import to_categorical
from keras.callbacks import EarlyStopping
from keras.wrappers.scikit_learn import KerasClassifier

def data_split(df, y_col, to_drop=[], random_state=None, hold1_size=.1, hold2_size=.1, hold3_size=.1):
    """ Splits the dataframe into the train set and 3 hold-out sets.

    Drops columns to drop and the target variable from the DataFrame df. Then the rows are reshuffled and split into 4 groups: train set and 3 hold-out sets.

    Args:
        df: pandas DataFrame with the data.
        y_col: the name of the column with the target variable.
        to_drop: list of columns to drop from further analysis.
        random_state: the seed used by the random number generator.
        hold1_size: the size of the first hold-out set as a fraction of total.
        hold2_size: the size of the second hold-out set as a fraction of total.
        hold3_size: the size of the third hold-out set as a fraction of total.

    Returns:
        A tuple of length 9 containing train set, 3 hold-out sets split of inputs and a list of column labels.
    """
    df_filtered = df.drop(columns=to_drop)
    rows = list(df_filtered.index)
    if random_state is not None:
        random.seed(random_state)
    random.shuffle(rows)
    length = len(rows)
    train_rows = rows[:int(length * (1 - (hold1_size + hold2_size + hold3_size)))]
    hold1_rows = rows[int(length * (1 - (hold1_size + hold2_size + hold3_size))):int(
        length * (1 - (hold2_size + hold3_size)))]
    hold2_rows = rows[int(length * (1 - (hold1_size + hold3_size))):int(length * (1 - hold3_size))]
    hold3_rows = rows[int(length * (1 - hold3_size)):]
    X_train = df_filtered.drop(columns=[y_col]).iloc[train_rows].values
    y_train = df_filtered.loc[train_rows, y_col].values
    X_hold1 = df_filtered.drop(columns=[y_col]).iloc[hold1_rows].values
    y_hold1 = df_filtered.loc[hold1_rows, y_col].values
    X_hold2 = df_filtered.drop(columns=[y_col]).iloc[hold2_rows].values
    y_hold2 = df_filtered.loc[hold2_rows, y_col].values
    X_hold3 = df_filtered.drop(columns=[y_col]).iloc[hold3_rows].values
    y_hold3 = df_filtered.loc[hold3_rows, y_col].values
    cols = df_filtered.drop(columns=[y_col]).columns
    return X_train, y_train, X_hold1, y_hold1, X_hold2, y_hold2, X_hold3, y_hold3, cols


def test_model(X_train, y_train, X_valid, y_valid, clf, oob_score=False, test='Validation'):
    """ Performes a model diagnostics with the training and validation sets.

    Makes predictions using the provided model on the training set and validation sets. Plots confusion matrices for each set.
    Returns the following diagnostic scores: precision score, recall score, F1 score, Fbeta score with beta=0.2, Mattews correlation coefficient,
    accuracy score, out-of-bag score.

    Args:
        X_train, y_train, X_valid, y_valid: trainig and validation sets.
        clf: classification model to be diagnosed.
        oob_score: boolean, indicating whether to include the out-of-bag scores calculated on the training data into the report.

    Returns:
        A pandas DataFrame with the diagnostic scores performed on the data sets.
    """
    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))
    sns.heatmap(confusion_matrix(y_train, clf.predict(X_train)), cmap=plt.cm.Blues, square=True, annot=True, fmt='d',
                vmin=0, ax=ax1);
    ax1.set_title('Training data')
    sns.heatmap(confusion_matrix(y_valid, clf.predict(X_valid)), cmap=plt.cm.Blues, square=True, annot=True, fmt='d',
                vmin=0, ax=ax2);
    ax2.set_title('{} data'.format(test));
    plt.tight_layout();
    y_train_pred = clf.predict(X_train)
    y_valid_pred = clf.predict(X_valid)
    score_table = pd.DataFrame(columns=['training data', 'validation data'])
    score_table.loc['roc_auc_score', 'training data'] = roc_auc_score(y_train, y_train_pred)
    score_table.loc['precision score', 'training data'] = precision_score(y_train, y_train_pred)
    score_table.loc['recall score', 'training data'] = recall_score(y_train, y_train_pred)
    score_table.loc['F1 score', 'training data'] = f1_score(y_train, y_train_pred)
    score_table.loc['Fbeta score', 'training data'] = fbeta_score(y_train, y_train_pred, beta=0.2)
    score_table.loc['Mattews correlation coefficient', 'training data'] = matthews_corrcoef(y_train, y_train_pred)
    score_table.loc['accuracy score', 'training data'] = accuracy_score(y_train, y_train_pred)
    score_table.loc['roc_auc_score', 'validation data'] = roc_auc_score(y_valid, y_valid_pred)
    score_table.loc['precision score', 'validation data'] = precision_score(y_valid, y_valid_pred)
    score_table.loc['recall score', 'validation data'] = recall_score(y_valid, y_valid_pred)
    score_table.loc['F1 score', 'validation data'] = f1_score(y_valid, y_valid_pred)
    score_table.loc['Fbeta score', 'validation data'] = fbeta_score(y_valid, y_valid_pred, beta=0.2)
    score_table.loc['Mattews correlation coefficient', 'validation data'] = matthews_corrcoef(y_valid, y_valid_pred)
    score_table.loc['accuracy score', 'validation data'] = accuracy_score(y_valid, y_valid_pred)
    if oob_score:
        score_table.loc['out of bag score', 'training data'] = clf.oob_score_
    return score_table

# Function to create model, required for KerasClassifier
def create_model(neurons1=100, neurons2=50, dropout1=.8, dropout2=.8, n_cols=95):
    # create model
    model = Sequential()
    model.add(Dense(neurons1, activation='relu', input_shape=(n_cols, )))
    model.add(Dense(neurons2, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    # Compile model
    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    return model


def preproc(X_train, X_val, cat_cols, cols_to_keep):
    other_cols = [not c in cat_cols for c in cols_to_keep]
    input_list_train = []
    input_list_val = []

    # the cols to be embedded: rescaling to range [0, # values)
    for c in cat_cols:
        el_index = cols_to_keep.index(c)
        raw_vals = np.unique(np.concatenate((X_train, X_val), axis=0)[:, el_index])
        raw_vals.sort()
        val_map = {}
        for i in range(len(raw_vals)):
            val_map[raw_vals[i]] = i
        input_list_train.append(np.vectorize(val_map.get)(X_train[:, el_index]))
        input_list_val.append(np.vectorize(val_map.get)(X_val[:, el_index]))

    # the rest of the columns
    input_list_train.append(X_train[:, other_cols])
    input_list_val.append(X_val[:, other_cols])

    return input_list_train, input_list_val

def build_embedding_network(X_train, X_val, cat_cols, cols_to_keep, n_num=100, n=60, d=False, verbose=False):
    inputs = []
    embeddings = []
    # models = []
    for categorical_var in cat_cols:
        if verbose:
            print("------------------------------------------------------------------")
            print("for categoical column ", categorical_var)
        input_cat = Input(shape=(1,))
        el_index = cols_to_keep.index(categorical_var)
        no_of_unique_cat = np.unique(np.concatenate((X_train, X_val), axis=0)[:, el_index]).size
        if verbose:
            print("number of unique cat", no_of_unique_cat)
        embedding_size = min(np.ceil((no_of_unique_cat) / 2), 50)
        embedding_size = int(embedding_size)
        if verbose:
            print("embedding_size set as ", embedding_size)
        embedding = Embedding(no_of_unique_cat + 1, embedding_size, input_length=1)(input_cat)
        embedding = Reshape(target_shape=(embedding_size,))(embedding)
        inputs.append(input_cat)
        embeddings.append(embedding)

    other_cols = [not c in cat_cols for c in cols_to_keep]
    len_other_cols = len([c for c in other_cols if c])
    if verbose:
        print("------------------------------------------------------------------")
        print('Numeric columns')
        print('Number of columns', len_other_cols)
    input_numeric = Input(shape=(len_other_cols,))
    embedding_numeric = Dense(n_num)(input_numeric)
    inputs.append(input_numeric)
    embeddings.append(embedding_numeric)

    x = Concatenate()(embeddings)
    x = Dense(n, activation='relu')(x)
    if d:
        x = Dropout(d)(x)
    x = Dense(n, activation='relu')(x)
    if d:
        x = Dropout(d)(x)
    output = Dense(1, activation='sigmoid')(x)

    model = Model(inputs, output)

    model.compile(loss='binary_crossentropy', optimizer='adam')
    return model

def grid_search(estimator, param_grid, X_train, y_train, X_test, y_test, nn=False):
    out = pd.DataFrame()
    for g in ParameterGrid(param_grid):
        estimator.set_params(**g)
        if nn:
            print('Fitting with params:', g)
            # Define early_stopping_monitor
            early_stopping_monitor = EarlyStopping(patience=2)

            # Fit the model
            estimator.fit(
                X_train,
                y_train,
                verbose=True,
                validation_split=0.3,
                epochs=1000,
                batch_size=10000,
                callbacks=[early_stopping_monitor])
            y_train_pred_prob_true = estimator.predict_proba(X_train)[:, 1]
            y_test_pred_prob_true = estimator.predict_proba(X_test)[:, 1]
            scores = {
                'train_roc_auc': roc_auc_score(y_train, y_train_pred_prob_true),
                'test_roc_auc': roc_auc_score(y_test, y_test_pred_prob_true)
            }
            print('Scores after fitting:', scores)
        else:
            estimator.fit(X_train, y_train)
            y_train_pred = estimator.predict(X_train)
            y_train_pred_prob = estimator.predict_proba(X_train)[:,1]
            y_test_pred = estimator.predict(X_test)
            y_test_pred_prob = estimator.predict_proba(X_test)[:,1]
            scores = {'train_accuracy': accuracy_score(y_train, y_train_pred),
                     'test_accuracy': accuracy_score(y_test, y_test_pred),
                     'train_roc_auc': roc_auc_score(y_train, y_train_pred_prob),
                     'test_roc_auc': roc_auc_score(y_test, y_test_pred_prob)}
        out_dict = g.copy()
        out_dict.update(scores)
        print(out_dict)
        out = out.append(out_dict, ignore_index=True)
    return out


if __name__ == '__main__':
    main()