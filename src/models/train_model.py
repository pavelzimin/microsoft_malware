import pandas as pd
import numpy as np
from sklearn.metrics import recall_score, precision_score, confusion_matrix, accuracy_score, log_loss, auc, \
    matthews_corrcoef, f1_score, fbeta_score, roc_auc_score
import random
import matplotlib.pyplot as plt
import seaborn as sns

def data_split(df, y_col, to_drop=[], random_state=None, hold1_size=.1, hold2_size=.1, hold3_size=.1):
    """ Splits the dataframe into the train set and 3 hold-out sets.

    Drops columns to drop and the target variable from the DataFrame df. Then the rows are reshuffled and split into 4 groups: train set and 3 hold-out sets.

    Args:
        df: pandas DataFrame with the data.
        y_col: the name of the column with the target variable.
        to_drop: list of columns to drop from further analysis.
        random_state: the seed used by the random number generator.
        hold1_size: the size of the first hold-out set as a fraction of total.
        hold2_size: the size of the second hold-out set as a fraction of total.
        hold3_size: the size of the third hold-out set as a fraction of total.

    Returns:
        A tuple of length 9 containing train set, 3 hold-out sets split of inputs and a list of column labels.
    """
    df_filtered = df.drop(columns=to_drop)
    rows = list(df_filtered.index)
    if random_state is not None:
        random.seed(random_state)
    random.shuffle(rows)
    length = len(rows)
    train_rows = rows[:int(length * (1 - (hold1_size + hold2_size + hold3_size)))]
    hold1_rows = rows[int(length * (1 - (hold1_size + hold2_size + hold3_size))):int(
        length * (1 - (hold2_size + hold3_size)))]
    hold2_rows = rows[int(length * (1 - (hold1_size + hold3_size))):int(length * (1 - hold3_size))]
    hold3_rows = rows[int(length * (1 - hold3_size)):]
    X_train = df_filtered.drop(columns=[y_col]).iloc[train_rows].values
    y_train = df_filtered.loc[train_rows, y_col].values
    X_hold1 = df_filtered.drop(columns=[y_col]).iloc[hold1_rows].values
    y_hold1 = df_filtered.loc[hold1_rows, y_col].values
    X_hold2 = df_filtered.drop(columns=[y_col]).iloc[hold2_rows].values
    y_hold2 = df_filtered.loc[hold2_rows, y_col].values
    X_hold3 = df_filtered.drop(columns=[y_col]).iloc[hold3_rows].values
    y_hold3 = df_filtered.loc[hold3_rows, y_col].values
    cols = df_filtered.drop(columns=[y_col]).columns
    return X_train, y_train, X_hold1, y_hold1, X_hold2, y_hold2, X_hold3, y_hold3, cols


def test_model(X_train, y_train, X_valid, y_valid, clf, oob_score=False, test='Validation'):
    """ Performes a model diagnostics with the training and validation sets.

    Makes predictions using the provided model on the training set and validation sets. Plots confusion matrices for each set.
    Returns the following diagnostic scores: precision score, recall score, F1 score, Fbeta score with beta=0.2, Mattews correlation coefficient,
    accuracy score, out-of-bag score.

    Args:
        X_train, y_train, X_valid, y_valid: trainig and validation sets.
        clf: classification model to be diagnosed.
        oob_score: boolean, indicating whether to include the out-of-bag scores calculated on the training data into the report.

    Returns:
        A pandas DataFrame with the diagnostic scores performed on the data sets.
    """
    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))
    sns.heatmap(confusion_matrix(y_train, clf.predict(X_train)), cmap=plt.cm.Blues, square=True, annot=True, fmt='d',
                ax=ax1);
    ax1.set_title('Training data')
    sns.heatmap(confusion_matrix(y_valid, clf.predict(X_valid)), cmap=plt.cm.Blues, square=True, annot=True, fmt='d',
                ax=ax2);
    ax2.set_title('{} data'.format(test));
    plt.tight_layout();
    y_train_pred = clf.predict(X_train)
    y_valid_pred = clf.predict(X_valid)
    score_table = pd.DataFrame(columns=['training data', 'validation data'])
    score_table.loc['roc_auc_score', 'training data'] = roc_auc_score(y_train, y_train_pred)
    score_table.loc['precision score', 'training data'] = precision_score(y_train, y_train_pred)
    score_table.loc['recall score', 'training data'] = recall_score(y_train, y_train_pred)
    score_table.loc['F1 score', 'training data'] = f1_score(y_train, y_train_pred)
    score_table.loc['Fbeta score', 'training data'] = fbeta_score(y_train, y_train_pred, beta=0.2)
    score_table.loc['Mattews correlation coefficient', 'training data'] = matthews_corrcoef(y_train, y_train_pred)
    score_table.loc['accuracy score', 'training data'] = accuracy_score(y_train, y_train_pred)
    score_table.loc['roc_auc_score', 'validation data'] = roc_auc_score(y_valid, y_valid_pred)
    score_table.loc['precision score', 'validation data'] = precision_score(y_valid, y_valid_pred)
    score_table.loc['recall score', 'validation data'] = recall_score(y_valid, y_valid_pred)
    score_table.loc['F1 score', 'validation data'] = f1_score(y_valid, y_valid_pred)
    score_table.loc['Fbeta score', 'validation data'] = fbeta_score(y_valid, y_valid_pred, beta=0.2)
    score_table.loc['Mattews correlation coefficient', 'validation data'] = matthews_corrcoef(y_valid, y_valid_pred)
    score_table.loc['accuracy score', 'validation data'] = accuracy_score(y_valid, y_valid_pred)
    if oob_score:
        score_table.loc['out of bag score', 'training data'] = clf.oob_score_
    return score_table


if __name__ == '__main__':
    main()